{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# NIR EDA\n",
    "\n",
    "NIR is a new feature in the glacier mapper and needs to be tested. This script is mainly for visualization and some basic correlations. -> find out which features are most likely useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "\n",
    "# Add the parent directory to sys.path to allow imports from monthly_forecasting\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "    \"path_discharge\": \"../../../../data/discharge/digitized_kyrgyz_hydromet/kyrgyz_hydromet_discharge_daily_2000_2023_kgz_filtered_v2.csv\",\n",
    "    \"path_forcing\": \"../../../../data/forcing/ERA5_krg/HRU00003_forcing_2000-2023.csv\",\n",
    "    \"path_static_data\": \"../../../../GIS/ML_Sandro/ML_basin_attributes_v2.csv\",\n",
    "    \"path_to_sla\": \"../../../../data/sla_silvan/fsc_sla_timeseries_gapfilled.csv\",\n",
    "    \"path_to_nir\": \"../../../../data/sla_silvan/meanNIR_TS_allBasins.csv\",\n",
    "    \"path_to_sca\": None,\n",
    "    \"path_to_hru_shp\": None,\n",
    "    \"path_to_swe\": \"../../../../data/snow/kyrgyzstan_ts/SWE\",\n",
    "    \"path_to_hs\": \"../../../../data/snow/kyrgyzstan_ts/HS\",\n",
    "    \"path_to_rof\": \"../../../../data/snow/kyrgyzstan_ts/RoF\",\n",
    "    \"HRU_SWE\": \"HRU_00003\",\n",
    "    \"HRU_HS\": \"HRU_00003\",\n",
    "    \"HRU_ROF\": \"HRU_00003\",\n",
    "    \"model_home_path\": \"../../monthly_forecasting_models/GlacierMapper_Based\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monthly_forecasting.scr import data_loading as dl\n",
    "\n",
    "# supress logging from matplotlib\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_data(data_config: Dict[str, Any], path_config: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"\n",
    "    Load data using the data loading utilities.\n",
    "\n",
    "    Args:\n",
    "        data_config: Data configuration\n",
    "        path_config: Path configuration\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (data, static_data)\n",
    "    \"\"\"\n",
    "    # -------------- 1. Load Data ------------------------------\n",
    "    hydro_ca, static_df = dl.load_data(\n",
    "        path_discharge=path_config[\"path_discharge\"],\n",
    "        path_forcing=path_config[\"path_forcing\"],\n",
    "        path_static_data=path_config[\"path_static_data\"],\n",
    "        path_to_sca=path_config[\"path_to_sca\"],\n",
    "        path_to_swe=path_config[\"path_to_swe\"],\n",
    "        path_to_hs=path_config[\"path_to_hs\"],\n",
    "        path_to_rof=path_config[\"path_to_rof\"],\n",
    "        HRU_SWE=path_config[\"HRU_SWE\"],\n",
    "        HRU_HS=path_config[\"HRU_HS\"],\n",
    "        HRU_ROF=path_config[\"HRU_ROF\"],\n",
    "        path_to_sla=path_config.get(\"path_to_sla\", None),\n",
    "        path_to_nir=path_config.get(\"path_to_nir\", None),\n",
    "    )\n",
    "\n",
    "    # if log_discharge in columns - drop\n",
    "    if \"log_discharge\" in hydro_ca.columns:\n",
    "        hydro_ca.drop(columns=[\"log_discharge\"], inplace=True)\n",
    "\n",
    "    hydro_ca = hydro_ca.sort_values(\"date\")\n",
    "\n",
    "    hydro_ca[\"code\"] = hydro_ca[\"code\"].astype(int)\n",
    "\n",
    "    if \"CODE\" in static_df.columns:\n",
    "        static_df.rename(columns={\"CODE\": \"code\"}, inplace=True)\n",
    "    static_df[\"code\"] = static_df[\"code\"].astype(int)\n",
    "\n",
    "    return hydro_ca, static_df\n",
    "\n",
    "\n",
    "# Load the data\n",
    "hydro_ca, static_df = load_data(data_config, data_config)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# get the dimensions of the data\n",
    "print(f\"hydro_ca shape: {hydro_ca.shape}\")\n",
    "\n",
    "# get the dtype of each column\n",
    "print(hydro_ca.dtypes)\n",
    "\n",
    "# print head\n",
    "print(hydro_ca.iloc[5000:5005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = {\n",
    "    \"discharge\": [\n",
    "        {\n",
    "            \"operation\": \"mean\",\n",
    "            \"windows\": [\n",
    "                15,\n",
    "                30,\n",
    "            ],\n",
    "            \"lags\": {},\n",
    "        },\n",
    "    ],\n",
    "    \"P\": [{\"operation\": \"sum\", \"windows\": [15, 30], \"lags\": {}}],\n",
    "    \"T\": [{\"operation\": \"mean\", \"windows\": [15, 30], \"lags\": {}}],\n",
    "    \"fsc_basin\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"SLA_West\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"SLA_South\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"SLA_East\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"SLA_North\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"NIR\": [\n",
    "        {\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}},\n",
    "        {\"operation\": \"mean\", \"windows\": [30], \"lags\": {}},\n",
    "    ],\n",
    "    \"SWE\": [{\"operation\": \"mean\", \"windows\": [15, 30], \"lags\": {}}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monthly_forecasting.scr import FeatureExtractor as FE\n",
    "\n",
    "# Use FeatureExtractor for time series features\n",
    "extractor = FE.StreamflowFeatureExtractor(\n",
    "    feature_configs=feature_config,\n",
    "    prediction_horizon=30,\n",
    "    offset=30,\n",
    ")\n",
    "\n",
    "data = extractor.create_all_features(hydro_ca)\n",
    "\n",
    "# only keep the last day of the month\n",
    "data = data[data[\"date\"].dt.is_month_end]\n",
    "\n",
    "# merge static data based on code\n",
    "data = data.merge(static_df[[\"code\", \"gl_fr\"]], on=\"code\", how=\"left\")\n",
    "mask_no_glaciers = data[\"gl_fr\"] == 0.0\n",
    "\n",
    "# fill the NIR values with 0\n",
    "all_cols_with_nir = [col for col in data.columns if col.startswith(\"NIR_\")]\n",
    "data.loc[mask_no_glaciers, all_cols_with_nir] = 0.0\n",
    "\n",
    "data_with_no_glaciers = data[data[\"gl_fr\"] == 0.0]\n",
    "\n",
    "print(data_with_no_glaciers.describe())\n",
    "\n",
    "print(\"Features extracted successfully.\")\n",
    "print(f\"Feature data shape: {data.shape}\")\n",
    "# columns\n",
    "print(f\"Feature data columns: {data.columns.tolist()}\")\n",
    "\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "\n",
    "print(f\"Feature data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_correlation(\n",
    "    data: pd.DataFrame,\n",
    "    feature_col: str,\n",
    "    target_col: str,\n",
    "    *,\n",
    "    month_col: str = \"month\",\n",
    "    jitter: float = 0.2,\n",
    "    point_alpha: float = 0.8,\n",
    "    figsize: tuple[int, int] = (12, 6),\n",
    ") -> None:\n",
    "    \"\"\"Plot monthly correlation distribution between a feature and a target.\"\"\"\n",
    "    if month_col not in data.columns:\n",
    "        if \"date\" not in data.columns:\n",
    "            raise ValueError(\n",
    "                \"DataFrame must contain either 'date' or the month column.\"\n",
    "            )\n",
    "        data = data.copy()\n",
    "        data[month_col] = data[\"date\"].dt.month\n",
    "\n",
    "    required = {feature_col, target_col, month_col, \"code\", \"gl_fr\"}\n",
    "    missing = required.difference(data.columns)\n",
    "    if missing:\n",
    "        missing_str = \", \".join(sorted(missing))\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing_str}\")\n",
    "\n",
    "    gl_fractions = data[[\"code\", \"gl_fr\"]].drop_duplicates().set_index(\"code\")\n",
    "\n",
    "    correlations = (\n",
    "        data.groupby([month_col, \"code\"], dropna=False)\n",
    "        .apply(lambda df: df[feature_col].corr(df[target_col]))\n",
    "        .reset_index(name=\"correlation\")\n",
    "        .dropna(subset=[\"correlation\"])\n",
    "    )\n",
    "\n",
    "    # merge gl_fr\n",
    "    correlations = correlations.join(gl_fractions, on=\"code\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.boxplot(\n",
    "        data=correlations,\n",
    "        x=month_col,\n",
    "        y=\"correlation\",\n",
    "        fill=False,\n",
    "        color=\"lightgray\",\n",
    "    )\n",
    "    # color based on gl_fr\n",
    "    sns.stripplot(\n",
    "        data=correlations,\n",
    "        x=month_col,\n",
    "        y=\"correlation\",\n",
    "        hue=\"gl_fr\",\n",
    "        alpha=point_alpha,\n",
    "        palette=\"magma\",\n",
    "        jitter=jitter,\n",
    "    )\n",
    "    # add a color legend\n",
    "    plt.legend(title=\"gl_fr\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.title(f\"Correlation between {feature_col} and {target_col} by Month\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Correlation Coefficient\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation of NIR against the 'target' for each month and basin\n",
    "plot_monthly_correlation(\n",
    "    data, feature_col=\"NIR_roll_last_value_30\", target_col=\"target\"\n",
    ")\n",
    "# SLA\n",
    "plot_monthly_correlation(\n",
    "    data,\n",
    "    feature_col=\"SLA_South_roll_last_value_30\",\n",
    "    target_col=\"target\",\n",
    ")\n",
    "plot_monthly_correlation(\n",
    "    data,\n",
    "    feature_col=\"NIR_roll_last_value_30\",\n",
    "    target_col=\"fsc_basin_roll_last_value_30\",\n",
    ")\n",
    "plot_monthly_correlation(\n",
    "    data, feature_col=\"fsc_basin_roll_last_value_30\", target_col=\"target\"\n",
    ")\n",
    "plot_monthly_correlation(data, feature_col=\"T_roll_mean_30\", target_col=\"target\")\n",
    "plot_monthly_correlation(data, feature_col=\"P_roll_sum_30\", target_col=\"target\")\n",
    "# with the discharge lags\n",
    "plot_monthly_correlation(\n",
    "    data, feature_col=\"discharge_roll_mean_30\", target_col=\"target\"\n",
    ")\n",
    "plot_monthly_correlation(\n",
    "    data, feature_col=\"discharge_roll_mean_15\", target_col=\"target\"\n",
    ")\n",
    "# swe\n",
    "plot_monthly_correlation(data, feature_col=\"SWE_roll_mean_30\", target_col=\"target\")\n",
    "plot_monthly_correlation(data, feature_col=\"SWE_roll_mean_15\", target_col=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Whole feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = {\n",
    "    \"discharge\": [\n",
    "        {\"operation\": \"mean\", \"windows\": [7, 15, 30], \"lags\": {\"30\": [30, 330, 365]}},\n",
    "        {\"operation\": \"slope\", \"windows\": [7, 15], \"lags\": {}},\n",
    "        {\"operation\": \"peak_to_peak\", \"windows\": [30], \"lags\": {}},\n",
    "        {\"operation\": \"max\", \"windows\": [30], \"lags\": {}},\n",
    "    ],\n",
    "    \"P\": [{\"operation\": \"sum\", \"windows\": [15, 30], \"lags\": {\"15\": [-15], \"30\": [30]}}],\n",
    "    \"T\": [\n",
    "        {\n",
    "            \"operation\": \"mean\",\n",
    "            \"windows\": [5, 15, 30],\n",
    "            \"lags\": {\"15\": [-15], \"30\": [30]},\n",
    "        },\n",
    "        {\"operation\": \"slope\", \"windows\": [5, 15], \"lags\": {\"15\": [-15]}},\n",
    "        {\"operation\": \"max\", \"windows\": [30], \"lags\": {}},\n",
    "        {\"operation\": \"min\", \"windows\": [30], \"lags\": {}},\n",
    "    ],\n",
    "    \"SLA_Avr\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {\"30\": [365]}}],\n",
    "    \"gla_fsc_total\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "    \"fsc_basin\": [\n",
    "        {\"operation\": \"last_value\", \"windows\": [30], \"lags\": {\"30\": [10, 20, 30]}},\n",
    "        {\n",
    "            \"operation\": \"mean_difference\",\n",
    "            \"windows\": [20, 30],\n",
    "            \"lags\": {\"20\": [10, 20, 30]},\n",
    "        },\n",
    "    ],\n",
    "    \"NIR\": [{\"operation\": \"last_value\", \"windows\": [30], \"lags\": {}}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features\n",
    "data_mm = hydro_ca.copy()\n",
    "code_drop = []\n",
    "for code in data_mm[\"code\"].unique():\n",
    "    mask_code = data_mm[\"code\"] == code\n",
    "    if code not in static_df[\"code\"].values:\n",
    "        logger.warning(f\"Code {code} not found in static data. Skipping.\")\n",
    "        code_drop.append(code)\n",
    "        continue\n",
    "    area_km2 = static_df.loc[static_df[\"code\"] == code, \"area_km2\"].values[0]\n",
    "    data_mm.loc[mask_code, \"discharge\"] = (\n",
    "        data_mm.loc[mask_code, \"discharge\"] * 86400 * 30 / (area_km2 * 1e6)\n",
    "    )\n",
    "\n",
    "if code_drop:\n",
    "    data_mm = data_mm[~data_mm[\"code\"].isin(code_drop)]\n",
    "\n",
    "\n",
    "extractor = FE.StreamflowFeatureExtractor(\n",
    "    feature_configs=feature_config,\n",
    "    prediction_horizon=30,\n",
    "    offset=30,\n",
    ")\n",
    "data = extractor.create_all_features(data_mm)\n",
    "\n",
    "static_df = static_df[[\"code\", \"gl_fr\"]]\n",
    "static_df[\"code\"] = static_df[\"code\"].astype(int)\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data = data.merge(static_df, on=\"code\", how=\"left\")\n",
    "\n",
    "\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Partial Correlation Analysis\n",
    "\n",
    "Analyze the partial correlation between NIR and target, controlling for discharge, T, and P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_correlations(\n",
    "    data: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    covar_cols: list[str],\n",
    "    *,\n",
    "    month_col: str = \"month\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate partial correlation between x and y, controlling for covariates.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame containing the data\n",
    "        x_col: Name of the x variable column (e.g., 'NIR_roll_last_value_30')\n",
    "        y_col: Name of the y variable column (e.g., 'target')\n",
    "        covar_cols: List of covariate column names to control for\n",
    "        month_col: Name of the month column\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with partial correlations for each code and month\n",
    "    \"\"\"\n",
    "    required = {x_col, y_col, month_col, \"code\"}.union(set(covar_cols))\n",
    "    missing = required.difference(data.columns)\n",
    "    if missing:\n",
    "        missing_str = \", \".join(sorted(missing))\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for month in sorted(data[month_col].unique()):\n",
    "        for code in sorted(data[\"code\"].unique()):\n",
    "            # Filter data for this month and code\n",
    "            mask = (data[month_col] == month) & (data[\"code\"] == code)\n",
    "            subset = data.loc[mask, [x_col, y_col] + covar_cols].dropna()\n",
    "\n",
    "            # Need at least n_covariates + 3 observations for partial correlation\n",
    "            if len(subset) < len(covar_cols) + 3:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Calculate partial correlation using pingouin\n",
    "                pcorr = pg.partial_corr(\n",
    "                    data=subset,\n",
    "                    x=x_col,\n",
    "                    y=y_col,\n",
    "                    covar=covar_cols,\n",
    "                )\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"month\": month,\n",
    "                        \"code\": code,\n",
    "                        \"partial_correlation\": pcorr[\"r\"].values[0],\n",
    "                        \"p_value\": pcorr[\"p-val\"].values[0],\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # Skip if calculation fails\n",
    "                logger.debug(f\"Failed for month={month}, code={code}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def plot_monthly_partial_correlation(\n",
    "    partial_corr_df: pd.DataFrame,\n",
    "    gl_fractions: pd.DataFrame,\n",
    "    x_col: str,\n",
    "    y_col: str,\n",
    "    covar_names: list[str],\n",
    "    *,\n",
    "    jitter: float = 0.2,\n",
    "    point_alpha: float = 0.8,\n",
    "    figsize: tuple[int, int] = (12, 6),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots of partial correlations by month.\n",
    "\n",
    "    Args:\n",
    "        partial_corr_df: DataFrame with columns ['month', 'code', 'partial_correlation']\n",
    "        gl_fractions: DataFrame with glacier fractions indexed by code\n",
    "        x_col: Name of x variable (for title)\n",
    "        y_col: Name of y variable (for title)\n",
    "        covar_names: List of covariate names (for title)\n",
    "        jitter: Amount of jitter for strip plot\n",
    "        point_alpha: Transparency of points\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Merge glacier fractions\n",
    "    plot_data = partial_corr_df.merge(gl_fractions.reset_index(), on=\"code\", how=\"left\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.boxplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"partial_correlation\",\n",
    "        fill=False,\n",
    "        color=\"lightgray\",\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"partial_correlation\",\n",
    "        hue=\"gl_fr\",\n",
    "        alpha=point_alpha,\n",
    "        palette=\"magma\",\n",
    "        jitter=jitter,\n",
    "    )\n",
    "    plt.legend(title=\"gl_fr\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    covar_str = \", \".join(covar_names)\n",
    "    plt.title(f\"Partial Correlation: {x_col} vs {y_col}\\n(controlling for {covar_str})\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Partial Correlation Coefficient\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the earlier section for partial correlation analysis\n",
    "# We'll use the data from cell b36366a2 which has the month-end filtered data\n",
    "\n",
    "# Get glacier fractions for plotting\n",
    "gl_fractions = data[[\"code\", \"gl_fr\"]].drop_duplicates().set_index(\"code\")\n",
    "\n",
    "print(\"Calculating partial correlations for NIR vs target...\")\n",
    "print(\"Controlling for: discharge_roll_mean_30, T_roll_mean_30, P_roll_sum_30\")\n",
    "\n",
    "# Calculate partial correlations\n",
    "partial_corr_results = calculate_partial_correlations(\n",
    "    data=data,\n",
    "    x_col=\"NIR_roll_last_value_30\",\n",
    "    y_col=\"target\",\n",
    "    covar_cols=[\"discharge_roll_mean_15\", \"T_roll_mean_15\", \"P_roll_sum_30\"],\n",
    ")\n",
    "\n",
    "print(f\"\\nCalculated {len(partial_corr_results)} partial correlations\")\n",
    "print(\n",
    "    f\"across {partial_corr_results['code'].nunique()} codes and \"\n",
    "    f\"{partial_corr_results['month'].nunique()} months\"\n",
    ")\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(partial_corr_results[\"partial_correlation\"].describe())\n",
    "\n",
    "# Plot the results\n",
    "plot_monthly_partial_correlation(\n",
    "    partial_corr_df=partial_corr_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    x_col=\"NIR\",\n",
    "    y_col=\"target\",\n",
    "    covar_names=[\"discharge\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "# partial correlation of SLA vs target\n",
    "print(\"Calculating partial correlations for SLA_South vs target...\")\n",
    "print(\"Controlling for: discharge_roll_mean_30, T_roll_mean_30, P_roll_sum_30\")\n",
    "partial_corr_results = calculate_partial_correlations(\n",
    "    data=data,\n",
    "    x_col=\"SLA_South_roll_last_value_30\",\n",
    "    y_col=\"target\",\n",
    "    covar_cols=[\"discharge_roll_mean_15\", \"T_roll_mean_15\", \"P_roll_sum_30\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plot_monthly_partial_correlation(\n",
    "    partial_corr_df=partial_corr_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    x_col=\"SLA_South\",\n",
    "    y_col=\"target\",\n",
    "    covar_names=[\"discharge\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "partial_corr_results = calculate_partial_correlations(\n",
    "    data=data,\n",
    "    x_col=\"SLA_North_roll_last_value_30\",\n",
    "    y_col=\"target\",\n",
    "    covar_cols=[\"discharge_roll_mean_15\", \"T_roll_mean_15\", \"P_roll_sum_30\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plot_monthly_partial_correlation(\n",
    "    partial_corr_df=partial_corr_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    x_col=\"SLA_North\",\n",
    "    y_col=\"target\",\n",
    "    covar_names=[\"discharge\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "partial_corr_results = calculate_partial_correlations(\n",
    "    data=data,\n",
    "    x_col=\"fsc_basin_roll_last_value_30\",\n",
    "    y_col=\"target\",\n",
    "    covar_cols=[\"discharge_roll_mean_15\", \"T_roll_mean_15\", \"P_roll_sum_30\"],\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_monthly_partial_correlation(\n",
    "    partial_corr_df=partial_corr_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    x_col=\"fsc_basin\",\n",
    "    y_col=\"target\",\n",
    "    covar_names=[\"discharge\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "# partial correlation of discharge vs target\n",
    "partial_corr_results = calculate_partial_correlations(\n",
    "    data=data,\n",
    "    x_col=\"discharge_roll_mean_30\",\n",
    "    y_col=\"target\",\n",
    "    covar_cols=[\"T_roll_mean_15\", \"P_roll_sum_30\"],\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plot_monthly_partial_correlation(\n",
    "    partial_corr_df=partial_corr_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    x_col=\"discharge\",\n",
    "    y_col=\"target\",\n",
    "    covar_names=[\"T\", \"P\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## VIF (Variance Inflation Factor) Analysis\n",
    "\n",
    "Analyze multicollinearity by calculating VIF for NIR alongside other predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "def calculate_vif(\n",
    "    data: pd.DataFrame,\n",
    "    feature_cols: list[str],\n",
    "    *,\n",
    "    month_col: str = \"month\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate VIF (Variance Inflation Factor) for given features.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame containing the data\n",
    "        feature_cols: List of feature column names to calculate VIF for\n",
    "        month_col: Name of the month column\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with VIF values for each feature, code, and month\n",
    "    \"\"\"\n",
    "    required = set(feature_cols).union({month_col, \"code\"})\n",
    "    missing = required.difference(data.columns)\n",
    "    if missing:\n",
    "        missing_str = \", \".join(sorted(missing))\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for month in sorted(data[month_col].unique()):\n",
    "        for code in sorted(data[\"code\"].unique()):\n",
    "            # Filter data for this month and code\n",
    "            mask = (data[month_col] == month) & (data[\"code\"] == code)\n",
    "            subset = data.loc[mask, feature_cols].dropna()\n",
    "\n",
    "            # Need sufficient observations for VIF calculation\n",
    "            if len(subset) < len(feature_cols) + 2:\n",
    "                continue\n",
    "            # Check for zero variance columns\n",
    "            if (subset.std() == 0).any():\n",
    "                print(\n",
    "                    f\"Skipping month={month}, code={code} due to zero variance in features\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Calculate VIF for each feature\n",
    "                for i, feature in enumerate(feature_cols):\n",
    "                    vif_value = variance_inflation_factor(subset.values, i)\n",
    "\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"month\": month,\n",
    "                            \"code\": code,\n",
    "                            \"feature\": feature,\n",
    "                            \"vif\": vif_value,\n",
    "                        }\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                # Skip if calculation fails\n",
    "                logger.debug(f\"Failed for month={month}, code={code}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def plot_monthly_vif(\n",
    "    vif_df: pd.DataFrame,\n",
    "    gl_fractions: pd.DataFrame,\n",
    "    feature_name: str,\n",
    "    *,\n",
    "    jitter: float = 0.2,\n",
    "    point_alpha: float = 0.8,\n",
    "    figsize: tuple[int, int] = (12, 6),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots of VIF values by month for a specific feature.\n",
    "\n",
    "    Args:\n",
    "        vif_df: DataFrame with columns ['month', 'code', 'feature', 'vif']\n",
    "        gl_fractions: DataFrame with glacier fractions indexed by code\n",
    "        feature_name: Name of the feature to plot\n",
    "        jitter: Amount of jitter for strip plot\n",
    "        point_alpha: Transparency of points\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Filter for the specific feature\n",
    "    feature_data = vif_df[vif_df[\"feature\"] == feature_name].copy()\n",
    "\n",
    "    # Merge glacier fractions\n",
    "    plot_data = feature_data.merge(gl_fractions.reset_index(), on=\"code\", how=\"left\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.boxplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"vif\",\n",
    "        fill=False,\n",
    "        color=\"lightgray\",\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"vif\",\n",
    "        hue=\"gl_fr\",\n",
    "        alpha=point_alpha,\n",
    "        palette=\"magma\",\n",
    "        jitter=jitter,\n",
    "    )\n",
    "\n",
    "    # make y log scale\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    plt.title(f\"VIF Analysis: {feature_name}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"VIF Value\")\n",
    "    plt.axhline(5, color=\"orange\", linestyle=\"--\", label=\"VIF=5 (moderate)\")\n",
    "    plt.axhline(10, color=\"red\", linestyle=\"--\", label=\"VIF=10 (high)\")\n",
    "    plt.legend(title=\"gl_fr\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF for NIR and other key predictors\n",
    "feature_cols_for_vif = [\n",
    "    \"NIR_roll_last_value_30\",\n",
    "    \"discharge_roll_mean_15\",\n",
    "    \"T_roll_mean_15\",\n",
    "    \"P_roll_sum_30\",\n",
    "    # \"fsc_basin_roll_last_value_30\",\n",
    "]\n",
    "\n",
    "print(\"Calculating VIF for features...\")\n",
    "print(f\"Features: {', '.join(feature_cols_for_vif)}\")\n",
    "\n",
    "# Calculate VIF\n",
    "vif_results = calculate_vif(\n",
    "    data=data,\n",
    "    feature_cols=feature_cols_for_vif,\n",
    ")\n",
    "\n",
    "print(f\"\\nCalculated {len(vif_results)} VIF values\")\n",
    "print(\n",
    "    f\"across {vif_results['code'].nunique()} codes and \"\n",
    "    f\"{vif_results['month'].nunique()} months\"\n",
    ")\n",
    "\n",
    "# Summary statistics for each feature\n",
    "print(\"\\nVIF Summary by Feature:\")\n",
    "for feature in feature_cols_for_vif:\n",
    "    feature_vif = vif_results[vif_results[\"feature\"] == feature][\"vif\"]\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(feature_vif.describe())\n",
    "\n",
    "# Plot VIF for NIR\n",
    "print(\"\\nPlotting VIF for NIR...\")\n",
    "plot_monthly_vif(\n",
    "    vif_df=vif_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    feature_name=\"NIR_roll_last_value_30\",\n",
    ")\n",
    "\n",
    "# Plot VIF for other features for comparison\n",
    "print(\"\\nPlotting VIF for fsc_basin...\")\n",
    "plot_monthly_vif(\n",
    "    vif_df=vif_results,\n",
    "    gl_fractions=gl_fractions,\n",
    "    feature_name=\"fsc_basin_roll_last_value_30\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Predictability Analysis\n",
    "\n",
    "Predict NIR and fsc_basin using discharge, P, and T to assess how much these variables explain each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def calculate_predictability_r2(\n",
    "    data: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    predictor_cols: list[str],\n",
    "    *,\n",
    "    month_col: str = \"month\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Predict target using predictors and calculate R² for each code and month.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame containing the data\n",
    "        target_col: Name of the target variable column (e.g., 'NIR_roll_last_value_30')\n",
    "        predictor_cols: List of predictor column names\n",
    "        month_col: Name of the month column\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with R² values for each code and month\n",
    "    \"\"\"\n",
    "    required = {target_col, month_col, \"code\"}.union(set(predictor_cols))\n",
    "    missing = required.difference(data.columns)\n",
    "    if missing:\n",
    "        missing_str = \", \".join(sorted(missing))\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing_str}\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for month in sorted(data[month_col].unique()):\n",
    "        for code in sorted(data[\"code\"].unique()):\n",
    "            # Filter data for this month and code\n",
    "            mask = (data[month_col] == month) & (data[\"code\"] == code)\n",
    "            subset = data.loc[mask, [target_col] + predictor_cols].dropna()\n",
    "\n",
    "            # Need sufficient observations for regression\n",
    "            if len(subset) < len(predictor_cols) + 2:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Prepare data\n",
    "                X = subset[predictor_cols].values\n",
    "                y = subset[target_col].values\n",
    "\n",
    "                # Fit linear regression\n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "\n",
    "                # Calculate R²\n",
    "                y_pred = model.predict(X)\n",
    "                r2 = r2_score(y, y_pred)\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"month\": month,\n",
    "                        \"code\": code,\n",
    "                        \"r2\": r2,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # Skip if calculation fails\n",
    "                logger.debug(f\"Failed for month={month}, code={code}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def plot_monthly_r2(\n",
    "    r2_df: pd.DataFrame,\n",
    "    gl_fractions: pd.DataFrame,\n",
    "    target_name: str,\n",
    "    predictor_names: list[str],\n",
    "    *,\n",
    "    jitter: float = 0.2,\n",
    "    point_alpha: float = 0.8,\n",
    "    figsize: tuple[int, int] = (12, 6),\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots of R² values by month.\n",
    "\n",
    "    Args:\n",
    "        r2_df: DataFrame with columns ['month', 'code', 'r2']\n",
    "        gl_fractions: DataFrame with glacier fractions indexed by code\n",
    "        target_name: Name of target variable (for title)\n",
    "        predictor_names: List of predictor names (for title)\n",
    "        jitter: Amount of jitter for strip plot\n",
    "        point_alpha: Transparency of points\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    # Merge glacier fractions\n",
    "    plot_data = r2_df.merge(gl_fractions.reset_index(), on=\"code\", how=\"left\")\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.boxplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"r2\",\n",
    "        fill=False,\n",
    "        color=\"lightgray\",\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=plot_data,\n",
    "        x=\"month\",\n",
    "        y=\"r2\",\n",
    "        hue=\"gl_fr\",\n",
    "        alpha=point_alpha,\n",
    "        palette=\"magma\",\n",
    "        jitter=jitter,\n",
    "    )\n",
    "    plt.legend(title=\"gl_fr\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    predictor_str = \", \".join(predictor_names)\n",
    "    plt.title(f\"R² for predicting {target_name}\\nusing {predictor_str}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"R² Score\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors\n",
    "predictor_cols = [\"discharge_roll_mean_30\", \"T_roll_mean_30\", \"P_roll_sum_30\"]\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "# Calculate R² for predicting NIR\n",
    "print(\"Calculating R² for predicting NIR using discharge, T, and P...\")\n",
    "r2_nir = calculate_predictability_r2(\n",
    "    data=data,\n",
    "    target_col=\"NIR_roll_last_value_30\",\n",
    "    predictor_cols=predictor_cols,\n",
    ")\n",
    "\n",
    "print(f\"\\nCalculated {len(r2_nir)} R² values for NIR\")\n",
    "print(f\"across {r2_nir['code'].nunique()} codes and {r2_nir['month'].nunique()} months\")\n",
    "print(\"\\nNIR R² Summary:\")\n",
    "print(r2_nir[\"r2\"].describe())\n",
    "\n",
    "gl_fractions = data[[\"code\", \"gl_fr\"]].drop_duplicates().set_index(\"code\")\n",
    "\n",
    "# Plot R² for NIR\n",
    "plot_monthly_r2(\n",
    "    r2_df=r2_nir,\n",
    "    gl_fractions=gl_fractions,\n",
    "    target_name=\"NIR\",\n",
    "    predictor_names=[\"Q\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "# Calculate R² for predicting fsc_basin\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Calculating R² for predicting fsc_basin using T and P...\")\n",
    "r2_fsc = calculate_predictability_r2(\n",
    "    data=data,\n",
    "    target_col=\"fsc_basin_roll_last_value_30\",\n",
    "    predictor_cols=predictor_cols,\n",
    ")\n",
    "\n",
    "print(f\"\\nCalculated {len(r2_fsc)} R² values for fsc_basin\")\n",
    "print(f\"across {r2_fsc['code'].nunique()} codes and {r2_fsc['month'].nunique()} months\")\n",
    "print(\"\\nfsc_basin R² Summary:\")\n",
    "print(r2_fsc[\"r2\"].describe())\n",
    "\n",
    "# Plot R² for fsc_basin\n",
    "plot_monthly_r2(\n",
    "    r2_df=r2_fsc,\n",
    "    gl_fractions=gl_fractions,\n",
    "    target_name=\"fsc_basin\",\n",
    "    predictor_names=[\"Q\", \"T\", \"P\"],\n",
    ")\n",
    "\n",
    "# Compare the two\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Comparison of R² values:\")\n",
    "print(f\"Mean R² for NIR: {r2_nir['r2'].mean():.3f}\")\n",
    "print(f\"Mean R² for fsc_basin: {r2_fsc['r2'].mean():.3f}\")\n",
    "print(f\"\\nMedian R² for NIR: {r2_nir['r2'].median():.3f}\")\n",
    "print(f\"Median R² for fsc_basin: {r2_fsc['r2'].median():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors\n",
    "predictor_cols = [\"discharge_roll_mean_30\", \"T_roll_mean_30\", \"P_roll_sum_30\"]\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "# Calculate R² for predicting NIR\n",
    "print(\"Calculating R² for predicting NIR using discharge, T, and P...\")\n",
    "r2_nir = calculate_predictability_r2(\n",
    "    data=data,\n",
    "    target_col=\"SWE_roll_mean_30\",\n",
    "    predictor_cols=predictor_cols,\n",
    ")\n",
    "\n",
    "print(f\"\\nCalculated {len(r2_nir)} R² values for NIR\")\n",
    "print(f\"across {r2_nir['code'].nunique()} codes and {r2_nir['month'].nunique()} months\")\n",
    "print(\"\\nNIR R² Summary:\")\n",
    "print(r2_nir[\"r2\"].describe())\n",
    "\n",
    "gl_fractions = data[[\"code\", \"gl_fr\"]].drop_duplicates().set_index(\"code\")\n",
    "\n",
    "# Plot R² for NIR\n",
    "plot_monthly_r2(\n",
    "    r2_df=r2_nir,\n",
    "    gl_fractions=gl_fractions,\n",
    "    target_name=\"SWE\",\n",
    "    predictor_names=[\"Q\", \"T\", \"P\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monthly-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
